{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torch Reptile Repository",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tda4Yz3rG2v7"
      },
      "source": [
        "# **Automated Machine Learning**\n",
        "\n",
        "---\n",
        "\n",
        "### **Torch Reptile - Parallel Metalearning**\n",
        "*Fall 2020 | Ruduan B.F. Plug*\n",
        "\n",
        "---\n",
        "\n",
        "<font size=\"1\">*Based on the Original Implementation by Alex Nichol & John Schulman [[1]](https://openai.com/blog/reptile/)*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzQ1T6HWX-S5"
      },
      "source": [
        "### Meta Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuqzrXatX_j1"
      },
      "source": [
        "# System Utility\n",
        "import sys\n",
        "\n",
        "# IPython Notebook Utilities\n",
        "from IPython.display import clear_output\n",
        "import tqdm.notebook as tqdm\n",
        "clear_output()\n",
        "\n",
        "# Google Colab Utilities\n",
        "from google.colab import files\n",
        "print(sys.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHOC5HMhP3sA"
      },
      "source": [
        "### Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ0KiCd6P34h"
      },
      "source": [
        "# Data Processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Model Library\n",
        "import tensorflow as tf\n",
        "\n",
        "# Parallel Compute\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Utility Libraries\n",
        "import random\n",
        "import math\n",
        "from time import time\n",
        "from copy import deepcopy\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize Device\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Torch Version\\t\", torch.__version__)\n",
        "print(\"Using Device\\t\", torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahVLMwR55Rsz"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM48Nv385dcL"
      },
      "source": [
        "data_folder = \"data\"\r\n",
        "np.random.seed(int(time()))\r\n",
        "torch.manual_seed(int(time()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFHo5IKxtA_L"
      },
      "source": [
        "### Reptile TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xti4UH95t4TI"
      },
      "source": [
        "#### Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TEFbIOEtIR2"
      },
      "source": [
        "class Reptile:\r\n",
        "\r\n",
        "  def __init__(self, model, log, params):\r\n",
        "\r\n",
        "    # Intialize Reptile Parameters\r\n",
        "    self.inner_step_size = params[0]\r\n",
        "    self.inner_batch_size = params[1]\r\n",
        "    self.outer_step_size = params[2]\r\n",
        "    self.outer_iterations = params[3]\r\n",
        "    self.meta_batch_size = params[4] \r\n",
        "    self.eval_iterations = params[5] \r\n",
        "    self.eval_batch_size = params[6]\r\n",
        "\r\n",
        "    # Initialize Torch Model and Tensorboard\r\n",
        "    self.model = model.to(device)\r\n",
        "    self.log = log\r\n",
        "\r\n",
        "  def reset(self):\r\n",
        "\r\n",
        "    # Reset Training Gradients\r\n",
        "    self.model.zero_grad()\r\n",
        "    self.current_loss = 0\r\n",
        "    self.current_batch = 0\r\n",
        "\r\n",
        "  def train(self, task):\r\n",
        "\r\n",
        "    # Train from Scratch\r\n",
        "    self.reset()\r\n",
        "\r\n",
        "    # Outer Training Loop\r\n",
        "    for outer_iteration in tqdm.tqdm(range(self.outer_iterations)):\r\n",
        "\r\n",
        "      # Track Current Weights\r\n",
        "      current_weights = deepcopy(self.model.state_dict())\r\n",
        "\r\n",
        "      # Sample a new Subtask\r\n",
        "      samples, task_theta = sample(task)\r\n",
        "\r\n",
        "      # Inner Training Loop\r\n",
        "      for inner_iteration in range(self.inner_batch_size):\r\n",
        "\r\n",
        "        # Process Meta Learning Batches\r\n",
        "        for batch in range(0, len(sample_space), self.meta_batch_size):\r\n",
        "\r\n",
        "          # Get Permuted Batch from Sample\r\n",
        "          perm = np.random.permutation(len(sample_space))\r\n",
        "          idx = perm[batch: batch + self.meta_batch_size][:, None]\r\n",
        "\r\n",
        "          # Calculate Batch Loss\r\n",
        "          batch_loss = self.loss(sample_space[idx], samples[idx])\r\n",
        "          batch_loss.backward()\r\n",
        "\r\n",
        "          # Update Model Parameters\r\n",
        "          for theta in self.model.parameters():\r\n",
        "\r\n",
        "            # Get Parameter Gradient\r\n",
        "            grad = theta.grad.data\r\n",
        "\r\n",
        "            # Update Model Parameter\r\n",
        "            theta.data -= self.inner_step_size * grad\r\n",
        "\r\n",
        "          # Update Model Loss from Torch Model Tensor\r\n",
        "          loss_tensor = batch_loss.cpu()\r\n",
        "          self.current_loss += loss_tensor.data.numpy()\r\n",
        "          self.current_batch += 1\r\n",
        "\r\n",
        "      # Linear Cooling Schedule\r\n",
        "      alpha = self.outer_step_size * (1 - outer_iteration / self.outer_iterations)\r\n",
        "\r\n",
        "      # Get Current Candidate Weights\r\n",
        "      candidate_weights = self.model.state_dict()\r\n",
        "\r\n",
        "      # Transfer Candidate Weights to Model State Checkpoint\r\n",
        "      state_dict = {candidate: (current_weights[candidate] + alpha * \r\n",
        "                               (candidate_weights[candidate] - current_weights[candidate])) \r\n",
        "                                for candidate in candidate_weights}\r\n",
        "      self.model.load_state_dict(state_dict)\r\n",
        "      \r\n",
        "      # Log new Training Loss\r\n",
        "      self.log.add_scalars('Model Estimate/Loss', \r\n",
        "                           {'Loss' : self.current_loss / self.current_batch}, \r\n",
        "                           outer_iteration)\r\n",
        "\r\n",
        "  def loss(self, x, y):\r\n",
        "\r\n",
        "    # Reset Torch Gradient\r\n",
        "    self.model.zero_grad()\r\n",
        "\r\n",
        "    # Calculate Torch Tensors\r\n",
        "    x = torch.tensor(x, device = device, dtype = torch.float32)\r\n",
        "    y = torch.tensor(y, device = device, dtype = torch.float32)\r\n",
        "\r\n",
        "    # Estimate over Sample\r\n",
        "    yhat = self.model(x)\r\n",
        "\r\n",
        "    # Regression Loss over Estimate\r\n",
        "    loss = nn.MSELoss()\r\n",
        "    output = loss(yhat, y)\r\n",
        "\r\n",
        "    return output\r\n",
        "\r\n",
        "  def predict(self, x):\r\n",
        "\r\n",
        "    # Estimate using Torch Model\r\n",
        "    t = torch.tensor(x, device = device, dtype = torch.float32)\r\n",
        "    t = self.model(t)\r\n",
        "\r\n",
        "    # Bring Torch Tensor from GPU to System Host Memory\r\n",
        "    t = t.cpu()\r\n",
        "\r\n",
        "    # Return Estimate as Numpy Float\r\n",
        "    y = t.data.numpy()\r\n",
        "\r\n",
        "    return y\r\n",
        "\r\n",
        "  def eval(self, base_truth, meta_batch_size, gradient_steps, inner_step_size):\r\n",
        "\r\n",
        "    # Sample Points from Task Sample Space\r\n",
        "    x, y = sample_points(base_truth, self.meta_batch_size)\r\n",
        "\r\n",
        "    # Model Base Estimate over Sample Space\r\n",
        "    estimate = [self.predict(sample_space[:,None])]\r\n",
        "\r\n",
        "    # Store Meta-Initialization Weights\r\n",
        "    meta_weights = deepcopy(self.model.state_dict())\r\n",
        "\r\n",
        "    # Get Estimate Loss over Meta-Initialization\r\n",
        "    loss_t = self.loss(x,y).cpu()\r\n",
        "    meta_loss = loss_t.data.numpy()\r\n",
        "\r\n",
        "    # Calculcate Estimate over Gradient Steps\r\n",
        "    for step in range(gradient_steps):\r\n",
        "\r\n",
        "      # Calculate Evaluation Loss and Backpropagate\r\n",
        "      eval_loss = self.loss(x,y)\r\n",
        "      eval_loss.backward()\r\n",
        "\r\n",
        "      # Update Model Estimate Parameters\r\n",
        "      for theta in self.model.parameters():\r\n",
        "\r\n",
        "        # Get Parameter Gradient\r\n",
        "        grad = theta.grad.data\r\n",
        "\r\n",
        "        # Update Model Parameter\r\n",
        "        theta.data -= self.inner_step_size * grad\r\n",
        "\r\n",
        "      # Update Estimate over Sample Space\r\n",
        "      estimate.append(self.predict(sample_space[:, None]))\r\n",
        "\r\n",
        "    # Get Estimate Loss over Evaluation\r\n",
        "    loss_t = self.loss(x,y).cpu()\r\n",
        "    estimate_loss = loss_t.data.numpy()\r\n",
        "    evaluation_loss = abs(meta_loss - estimate_loss)/meta_batch_size\r\n",
        "    \r\n",
        "    # Restore Meta-Initialization Weights\r\n",
        "    self.model.load_state_dict(meta_weights)\r\n",
        "\r\n",
        "    return estimate, evaluation_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARn0cnaCT4I6"
      },
      "source": [
        "#### PyTorch Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzQaKtGLT4YP"
      },
      "source": [
        "class TorchModule(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, n):\r\n",
        "\r\n",
        "    # Initialize PyTorch Base Module\r\n",
        "    super(TorchModule, self).__init__()\r\n",
        "\r\n",
        "    # Define Multi-Layer Perceptron\r\n",
        "    self.input = nn.Linear(1,n)\r\n",
        "    self.hidden_in = nn.Linear(n,n)\r\n",
        "    self.hidden_out = nn.Linear(n,n)\r\n",
        "    self.output = nn.Linear(n,1)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "\r\n",
        "    # PyTorch Feed Forward Subroutine\r\n",
        "    x = torch.tanh(self.input(x))\r\n",
        "    x = torch.tanh(self.hidden_in(x))\r\n",
        "    x = torch.tanh(self.hidden_out(x))\r\n",
        "    y = self.output(x)\r\n",
        "\r\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdfjr05yiF_T"
      },
      "source": [
        "### Learning Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2O25f8RUHmr"
      },
      "source": [
        "#### Task Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNUMR1Z3iGUi"
      },
      "source": [
        "def logistic(x, theta):\r\n",
        "\r\n",
        "  return theta[0] / (1 + np.exp(-1 * theta[1] * ( x - theta[2])))\r\n",
        "\r\n",
        "def normal(x, theta):\r\n",
        "\r\n",
        "  return 1/(theta[1] * np.sqrt(2 * np.pi)) * np.exp(-1/2 * np.power((x-theta[0])/theta[1],2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAf2MjOoUKL8"
      },
      "source": [
        "#### Task Sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhxxbAe1ULpM"
      },
      "source": [
        "def sample(task):\r\n",
        "\r\n",
        "  if task is (not normal or not logistic):\r\n",
        "\r\n",
        "    raise NotImplementedError\r\n",
        "\r\n",
        "  # Parametric Generator for Task Distribution\r\n",
        "  theta = [np.random.uniform( 1,  5), \r\n",
        "           np.random.uniform( 0, 10),\r\n",
        "           np.random.uniform( 0, 10)]\r\n",
        "\r\n",
        "  return task(sample_space, theta), theta\r\n",
        "\r\n",
        "def sample_points(task, batch_size):\r\n",
        "\r\n",
        "  # Sample Random Points from Sample Space\r\n",
        "  idx = np.random.choice(np.arange(len(sample_space)), batch_size, replace = False)\r\n",
        "  return sample_space[idx[:,None]], task[idx[:,None]]\r\n",
        "\r\n",
        "def meta_sample(radius, count):\r\n",
        "\r\n",
        "  # Generate Sample Space of Specified Radius\r\n",
        "  sample_space = np.linspace(-radius, radius, count)\r\n",
        "  return sample_space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9W4j4rW0yuS"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDm4ny3Qt0em"
      },
      "source": [
        "# Define Experiment Parameters\r\n",
        "inner_step_size = 0.02\r\n",
        "inner_batch_size = 16\r\n",
        "\r\n",
        "outer_step_size = 0.1\r\n",
        "outer_iterations = 10000\r\n",
        "meta_batch_size = 32\r\n",
        "\r\n",
        "eval_iterations = 32\r\n",
        "eval_batch_size = 10\r\n",
        "eval_range = range(1,11)\r\n",
        "\r\n",
        "model_size = 32\r\n",
        "sample_radius = 20\r\n",
        "sample_count = 100\r\n",
        "\r\n",
        "params = [inner_step_size, inner_batch_size,\r\n",
        "          outer_step_size, outer_iterations, meta_batch_size,\r\n",
        "          eval_iterations, eval_batch_size]\r\n",
        "\r\n",
        "# Define Experiment Task and Model\r\n",
        "task = logistic\r\n",
        "log = SummaryWriter(data_folder)\r\n",
        "model = Reptile(TorchModule(model_size), log, params)\r\n",
        "\r\n",
        "# Train Model\r\n",
        "eval_mse = np.empty(shape=[len(eval_range), eval_batch_size])\r\n",
        "sample_space = meta_sample(sample_radius, sample_count)\r\n",
        "model.train(task)\r\n",
        "\r\n",
        "# Evaluate Model\r\n",
        "for batch in range(eval_batch_size):\r\n",
        "\r\n",
        "  samples, task_theta  = sample(task)\r\n",
        "\r\n",
        "  for sample_size in eval_range:\r\n",
        "\r\n",
        "    # Estimate Model for Batch\r\n",
        "    estimate, loss = model.eval(samples, sample_size, eval_iterations, inner_step_size)\r\n",
        "    eval_mse[sample_size-1, batch-1] = loss\r\n",
        "    \r\n",
        "    # Log Results to Tensorboard\r\n",
        "    for idx in range(len(samples)):\r\n",
        "        log.add_scalars('Model Evaluation {}/{} Samples'.format(batch + 1, sample_size), \r\n",
        "            {'Task': samples[idx], \r\n",
        "              'Baseline': estimate[0][idx][0], \r\n",
        "              'Estimate' : estimate[-1][idx][0]}, \r\n",
        "              idx)\r\n",
        "\r\n",
        "log.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jiPJ9EM9278"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SixEsDGC0y7s"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "%reload_ext tensorboard\r\n",
        "%tensorboard --logdir /content/data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}